{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2605145,"sourceType":"datasetVersion","datasetId":1533023}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/junhyeonkwon/using-yunet?scriptVersionId=171819978\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"### Create dataset.csv from input dataset","metadata":{}},{"cell_type":"code","source":"# repo includes \n#   face_detection_yunet_2023mar.onnx\n#   dataset.csv\n#   dataset_nfaces.csv\n!git clone https://github.com/luanakwon/Deepfake-Detection-MAICON2023.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-20T03:16:04.758926Z","iopub.execute_input":"2024-01-20T03:16:04.759411Z","iopub.status.idle":"2024-01-20T03:16:07.3185Z","shell.execute_reply.started":"2024-01-20T03:16:04.759372Z","shell.execute_reply":"2024-01-20T03:16:07.31734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm.notebook import tqdm\nimport shutil\nimport os\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:16:07.321476Z","iopub.execute_input":"2024-01-20T03:16:07.322018Z","iopub.status.idle":"2024-01-20T03:16:08.19227Z","shell.execute_reply.started":"2024-01-20T03:16:07.32197Z","shell.execute_reply":"2024-01-20T03:16:08.190829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read video from path\n# read total 64 frames\n# if a frame has more or less then 1 face -> move video to error\n# crop square area fitting bbox\n# resize to 384\n# return\ndef get_facecrops(detector, video_path, n_frame, max_t_len=0, scale=1, dsize=(384,384)):\n    if os.path.exists(video_path):\n        # info about video\n        cap = cv2.VideoCapture(video_path)\n        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        fps = cap.get(cv2.CAP_PROP_FPS)\n        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        length = min(length, int(max_t_len*fps)) if max_t_len>0 else length\n        skips = length // n_frame\n        \n        # set detector\n        detector.setInputSize((width, height))\n        \n        faces = []\n        count_skips = 0\n        bad_skips = 0\n        while cap.isOpened():\n            ret, frame = cap.read()\n            if ret:\n                if count_skips % skips == 0:\n                    ret2, det = detector.detect(frame)\n                    # wrong detection, try next frame\n                    if not ret2 or det is None or det.shape[0] != 1:\n                        bad_skips += 1\n                        # early stop - over 70% of the detects are useless\n                        if bad_skips > skips+(bad_skips + len(faces))*0.7:\n                            print(f\"Early stopping at {cap.get(cv2.CAP_PROP_POS_FRAMES)/fps:.3}s.. \", end=' ')\n                            cap.release()\n                            break\n                        continue\n                    # one face in frame\n                    else:\n                        faces.append(crop_from_image(frame, det, scale, dsize))\n                    # early stop - stop reading when all n frames are found\n                    if len(faces) >= n_frame:\n                        cap.release()\n                        break\n                count_skips += 1\n            else:\n                cap.release()\n                break\n        # if len(faces)  != n_frame   \n        if len(faces) != n_frame:\n            print(f\"Only found {len(faces)} face crops in {video_path.split('/')[-1]}\")\n        return faces\n    \ndef crop_from_image(frame, detection, scale, dsize):\n    # frame - image of shape (H, W, C)\n    # scale - float\n    # dsize - (H,W)\n    # detection - (1,15)\n    x, y = detection[0,0:2] # 0-1: x, y of bbox top left corner\n    width, height = detection[0,2:4] # 2-3: width, height of bbox\n    # 4-5: x, y of right eye (blue point in the example image)\n    # 6-7: x, y of left eye (red point in the example image)\n    # 8-9: x, y of nose tip (green point in the example image)\n    # 10-11: x, y of right corner of mouth (pink point in the example image)\n    # 12-13: x, y of left corner of mouth (yellow point in the example image)\n    # 14: face score\n    \n    # apply scale (up/down)\n    dx = width*(scale-1)/2\n    dy = height*(scale-1)/2\n    x = x-dx\n    y = y-dy\n    x2 = x+width*scale\n    y2 = y+height*scale\n    # adjust aspect ratio\n    r_in = height/width\n    r_out= dsize[0]/dsize[1]\n    if r_in > r_out: # in image taller, widen width\n        new_w = height/r_out\n        x -= (new_w-width)/2\n        x2 += (new_w-width)/2\n    elif r_in < r_out: # in image flatter\n        new_h = width*r_out\n        y -= (new_h-height)/2\n        y2 += (new_h-height)/2\n    # pad frame\n    top = 0 if y >= 0 else int(abs(y))\n    bottom = 0 if y2 < frame.shape[0] else int(y2-frame.shape[0])\n    left = 0 if x >= 0 else int(abs(x))\n    right = 0 if x2 < frame.shape[1] else int(x2-frame.shape[1])\n    frame = cv2.copyMakeBorder(\n        frame, top, bottom, left, right, borderType=cv2.BORDER_CONSTANT,value=0)\n    # crop \n    crop = frame[int(y+top):int(y2+top),int(x+left):int(x2+left)]\n    # resize crop to dsize\n    crop = cv2.resize(crop,(dsize[1],dsize[0]),fx=0,fy=0)\n    \n    return crop\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:16:08.194552Z","iopub.execute_input":"2024-01-20T03:16:08.19522Z","iopub.status.idle":"2024-01-20T03:16:08.225719Z","shell.execute_reply.started":"2024-01-20T03:16:08.195173Z","shell.execute_reply":"2024-01-20T03:16:08.223966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/working/Deepfake-Detection-MAICON2023/tmp_data/FaceDet_model_Yunet/face_detection_yunet_2023mar.onnx'\ndetector = cv2.FaceDetectorYN.create(model_path,\"\", (320, 320))\n\nos.makedirs('deepfake-detection-face-dataset', exist_ok=True)\n\ndf_nface_path = '/kaggle/working/Deepfake-Detection-MAICON2023/tmp_data/csv/dataset_nfaces.csv'\ndf_nface = pd.read_csv(df_nface_path)\n\ndf_nface.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:16:08.229658Z","iopub.execute_input":"2024-01-20T03:16:08.230194Z","iopub.status.idle":"2024-01-20T03:16:08.325963Z","shell.execute_reply.started":"2024-01-20T03:16:08.230148Z","shell.execute_reply":"2024-01-20T03:16:08.324622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _, row in tqdm(df_nface[df_nface['num_faces'] == 1].iterrows(),total=2549):\n    video_name = row['video']\n    video_path = row['path']\n    # make dir\n    dir_path = f\"deepfake-detection-face-dataset/{video_name.split('.')[0]}\"\n    if os.path.exists(dir_path):\n        shutil.rmtree(dir_path)\n    os.mkdir(dir_path)\n    \n    # get face crops\n    faces = get_facecrops(detector, video_path, n_frame=32, max_t_len = 30, scale=1.5)\n    # save face crops\n    for i,face in enumerate(faces):\n        face_path = os.path.join(dir_path,f\"{i:02}.jpg\")\n        cv2.imwrite(face_path,face)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:16:08.327726Z","iopub.execute_input":"2024-01-20T03:16:08.328459Z","iopub.status.idle":"2024-01-20T03:19:57.17309Z","shell.execute_reply.started":"2024-01-20T03:16:08.328414Z","shell.execute_reply":"2024-01-20T03:19:57.171943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create dataset.csv\n# columns video frame_id path label split\n\npath = glob('/kaggle/working/deepfake-detection-face-dataset/*/*')\npath = [p.lstrip('/kaggle/working/') for p in path]\nvideo = [p.split('/')[-2]+'.mp4' for p in path]\nframe_id = [int(p.split('/')[-1].rstrip('.jpg')) for p in path]\n\ndf1 = pd.read_csv('/kaggle/working/Deepfake-Detection-MAICON2023/tmp_data/csv/dataset.csv')\ndf2 = pd.DataFrame.from_dict(\n    {\n        'video' : video,\n        'frame_id' : frame_id,\n        'path' : path\n    }\n)\ndf1.drop(columns=['path'], inplace=True)\ndf = pd.merge(df2, df1, left_on='video',right_on='video',how='left')\ndf.sort_values(['split','path'],inplace=True)\nprint(len(df))\ndf.reset_index(drop=True, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:19:57.174701Z","iopub.execute_input":"2024-01-20T03:19:57.175571Z","iopub.status.idle":"2024-01-20T03:19:57.243402Z","shell.execute_reply.started":"2024-01-20T03:19:57.175512Z","shell.execute_reply":"2024-01-20T03:19:57.242239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('deepfake-detection-face-dataset.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:19:57.244816Z","iopub.execute_input":"2024-01-20T03:19:57.245847Z","iopub.status.idle":"2024-01-20T03:19:57.260875Z","shell.execute_reply.started":"2024-01-20T03:19:57.245811Z","shell.execute_reply":"2024-01-20T03:19:57.259498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r /kaggle/working/Deepfake-Detection-MAICON2023","metadata":{"execution":{"iopub.status.busy":"2024-01-20T03:19:57.262088Z","iopub.execute_input":"2024-01-20T03:19:57.263014Z","iopub.status.idle":"2024-01-20T03:19:58.38378Z","shell.execute_reply.started":"2024-01-20T03:19:57.262978Z","shell.execute_reply":"2024-01-20T03:19:58.382241Z"},"trusted":true},"execution_count":null,"outputs":[]}]}